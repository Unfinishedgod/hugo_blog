---
title: '[Langchain] PDFë¥¼ í•™ìŠµí•œ ë‚˜ë§Œì˜ ì±—ë´‡ streamlitì— ë°°í¬ í•˜ê¸°'
author: ìµœì˜ìš©
date: '2023-12-16'
slug: langchain-pdf-streamlit
categories:
  - Langchain
tags:
  - streamlit
  - langchain
---



<center>
<img src="images/main1.PNG" style="width:80.0%" />
</center>
<p>ì´ë²ˆì—ëŠ” langchainì„ ì‚¬ìš©í•˜ì—¬ ë‚˜ë§Œì˜ ì±—ë´‡ì„ ë§Œë“¤ê³ , streamlitì— ë°°í¬ í•´ë³´ì. ìµœê·¼ì— ì±…ì„ ì§‘í•„í•˜ê³ , ì±… ë‚´ìš© ëŒ€í•œ ì§ˆë¬¸ì„ ì¢…ì¢… ë°›ì•˜ì—ˆë‹¤. ì´ë•Œ ë¬¸ë“ ìƒê°ì´ ë‚¬ë‹¤.</p>
<center>
ì´ë•Œ ì±—ë´‡ì´ ìˆìœ¼ë©´ ë„ì›€ì´ ë˜ê² ëŠ”ë°? <br>
langchainì„ ì´ì°¸ì— ì ‘ëª© ì‹œì¼œì…” streamlit ëŒ€ì‹œë³´ë“œì— ë„£ì–´ ë³´ì.
</center>
<p>ê·¸ë˜ì„œ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ë§Œì˜ ì±—ë´‡ì„ ë§Œë“¤ì–´ ë³´ì•˜ë‹¤. ì£¼ì œëŠ” ì´ë²ˆì— ì¼ë˜ ì±…. â€˜ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ë°°ìš°ëŠ” íŒŒì´ì¬ ë¬¸ì œ í•´ê²°â€™</p>
<ul>
<li><a href="https://apartment-board.streamlit.app/%EC%A7%88%EC%9D%98%EC%9D%91%EB%8B%B5%EC%B1%97%EB%B4%87">ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ë°°ìš°ëŠ” íŒŒì´ì¬ ë¬¸ì œ í•´ê²° ì±—ë´‡</a></li>
</ul>
<center>
<img src="images/main.PNG" style="width:80.0%" />
</center>
<p>ê·¸ëŸ¼ í•˜ë‚˜ì”© ë§Œë“¤ì–´ë³´ì. ìš°ì„  ë§Œë“¤ë©´ì„œ ì°¸ê³ ë¥¼ í•´ì•¼í•  ë§í¬ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p>
<ul>
<li><a href="https://aifactory.space/task/2446/overview">ë„ì… ì‹œê¸‰! íšŒì‚¬ë‚´ê·œ ì±—ë´‡ ì§ì ‘ ë§Œë“¤ì–´ë³´ê¸° | ê¹€íƒœì˜</a></li>
<li><a href="https://www.youtube.com/watch?v=2yv4PxE1Ks0">ì¸ê³µì§€ëŠ¥íŒ©í† ë¦¬ ìœ íŠœë¸Œ-íšŒì‚¬ë‚´ê·œ ì±—ë´‡ ì§ì ‘ ë§Œë“¤ì–´ ë³´ê¸°</a></li>
<li><a href="https://docs.streamlit.io/library/api-reference/chat">Streamlit-Chat elements</a></li>
</ul>
<div id="langchainì„-ì‚¬ìš©í•œ-ë‚˜ë§Œì˜-ì±—ë´‡-ë§Œë“¤ê¸°" class="section level2">
<h2>Langchainì„ ì‚¬ìš©í•œ ë‚˜ë§Œì˜ ì±—ë´‡ ë§Œë“¤ê¸°</h2>
<div id="ë¼ì´ë¸ŒëŸ¬ë¦¬-ì„¤ì¹˜" class="section level3">
<h3>ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜</h3>
<p>ìš°ì„  ì´ë²ˆì— í•„ìš”í•œ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜ í•´ì£¼ì.</p>
<ul>
<li>pypdf
<ul>
<li>íŒŒì´ì¬ìœ¼ë¡œ pdfë¥¼ ì½ì–´ ì˜¤ê¸° ìœ„í•¨ì´ë‹¤. ê·¸ëŸ¬ë‚˜, pdfì—ì„œë„ ì½ì„ìˆ˜ ì—†ëŠ” ì´ë¯¸ì§€í˜• í…ìŠ¤íŠ¸ëŠ” ë¶ˆê°€.(í…ŒìŠ¤íŠ¸ í•´ë³´ë ¤ë©´ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸ê°€ ê°€ëŠ¥í•˜ë©´ ëœë‹¤.)</li>
</ul></li>
<li>chromadb
<ul>
<li>ì˜¤í”ˆì†ŒìŠ¤ ë²¡í„° ë°ì´í„° ë² ì´ìŠ¤ì´ë‹¤. ìµœê·¼ì— ë¶€ìƒí•˜ê³  ìˆëŠ” ë²¡í„° DBë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µí•œë‹¤. ë²¡í„° DBëŠ” ë‚˜ì¤‘ì— ê³µë¶€í• ë•Œ ìì„¸í•˜ê²Œ ë‹¤ë¤„ë³¼ ì˜ˆì •.</li>
<li>ì°¸ê³ ë¡œ í˜„ì‹œì (2023-12-17)ì—ì„œëŠ” íŒŒì´ì¬ 3.10ì´ ê°€ì¥ ì í•©í•˜ë‹¤.</li>
<li>3.11ì—ì„œëŠ” ì„¤ì¹˜ê°€ ì•ˆë˜ê³ , 3.9ì—ì„œëŠ” streamlitê³¼ì˜ í˜¸í™˜ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.</li>
</ul></li>
<li>tiktoken
<ul>
<li>íŒŒì´ì¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìì—°ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬. pdfë¥¼ ì½ì–´ì˜¤ê³  í† í°í™” ì‹œì¼œì„œ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤.</li>
</ul></li>
<li>langchain
<ul>
<li>LLMì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬.</li>
<li>ê³µì‹ë¬¸ì„œì—ì„œ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì— í•„ìš”í•˜ë©´ ì´ê³³ì—ì„œ ì—¬ëŸ¬ê°€ì§€ê³  ì°¸ê³  í•˜ë©´ ëœë‹¤.</li>
<li>ê³µì‹ë¬¸ì„œ: <a href="https://www.langchain.com/">www.langchain.com</a></li>
</ul></li>
</ul>
<pre class="bash"><code>pip install pypdf 
pip install chromadb
pip install tiktoken
pip install langchain</code></pre>
</div>
<div id="ë¼ì´ë¸ŒëŸ¬ë¦¬-ë¡œë“œ" class="section level3">
<h3>ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ</h3>
<p>ìš°ì„  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ ì˜¤ì. ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ ë‹¤ìŒì˜ ìœ íŠœë¸Œë¥¼ ê¼­ ì°¸ê³  í•˜ì.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=2yv4PxE1Ks0">ì¸ê³µì§€ëŠ¥íŒ©í† ë¦¬ ìœ íŠœë¸Œ-íšŒì‚¬ë‚´ê·œ ì±—ë´‡ ì§ì ‘ ë§Œë“¤ì–´ ë³´ê¸°</a></li>
</ul>
<pre class="python"><code>import os

from langchain.chat_models import ChatOpenAI

from langchain.document_loaders import PyPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.embeddings.cohere import CohereEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch
from langchain.vectorstores import Chroma

from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQAWithSourcesChain</code></pre>
<div id="openai-api-key-ë“±ë¡" class="section level4">
<h4>OpenAI API Key ë“±ë¡</h4>
<p>ì´ì œ OpenAIì˜ APIí‚¤ë¥¼ ë„£ì–´ ì£¼ì.</p>
<pre class="python"><code>os.environ[&quot;OPENAI_API_KEY&quot;] = &#39;OpenAI API í‚¤&#39;</code></pre>
</div>
<div id="pdf-ë¡œë“œ" class="section level4">
<h4>PDF ë¡œë“œ</h4>
<p>ê·¸ë¦¬ê³  ë‚˜ì„œ ìš°ë¦¬ê°€ í•„ìš”í•œ pdfë¥¼ ì½ì–´ ì˜¨ë‹¤. pypdfì˜ PyPDFLoader()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½ì–´ ì˜¨ë‹¤.</p>
<pre class="python"><code>loader = PyPDFLoader(&#39;ìƒ˜í”Œ.pdf&#39;)
documents = loader.load()</code></pre>
</div>
<div id="ë¬¸ì„œë¥¼-í…ìŠ¤íŠ¸ë¡œ-ë¶„í• -í•´ì£¼ì." class="section level4">
<h4>ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë¶„í•  í•´ì£¼ì.</h4>
<pre class="python"><code>text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)</code></pre>
<p>ìš°ë¦¬ê°€ pdfì—ì„œ ì½ì–´ì˜¨ í…ìŠ¤íŠ¸ë¥¼ ì»´í“¨í„°ê°€ ì‰½ê²Œ ì´í•´í•˜ê³  ì²˜ë¦¬ í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì´ë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ ì´ë¥¼ ë²¡í„°ë² ì´ìŠ¤ë¡œ ë³€í™˜ í•˜ì—¬ ì €ì¥ í•´ì£¼ì.</p>
<pre class="python"><code>embeddings = OpenAIEmbeddings()
vector_store = Chroma.from_documents(texts, embeddings)
retriever = vector_store.as_retriever(search_kwargs={&quot;k&quot;: 2})</code></pre>
</div>
</div>
<div id="í”„ë¡¬í”„íŠ¸-ê°œì„ " class="section level3">
<h3>í”„ë¡¬í”„íŠ¸ ê°œì„ </h3>
<p>í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„  í•˜ëŠ” ê³¼ì •ì´ë‹¤. ì´ë¥¼ í•˜ì§€ ì•Šìœ¼ë©´ ì˜ì–´ë¡œ ë‹µë³€ì„ í•˜ê²Œ ë˜ëŠ”ë°, system_templateì— í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•˜ëŠ” ë‚´ìš©ì„ ì¶”ê°€ í•´ì„œ ë” ë§¤ë„ëŸ½ê²Œ í•œê¸€ë¡œ ê²°ê³¼ë¥¼ ë‚˜ì˜¤ê²Œ í•´ì¤€ë‹¤. ì´ ì—­ì‹œ ìì„¸í•œ ì‚¬í•­ì€ ìœ íŠœë¸Œë¥¼ ì°¸ê³  í•œë‹¤.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=2yv4PxE1Ks0">ì¸ê³µì§€ëŠ¥íŒ©í† ë¦¬ ìœ íŠœë¸Œ-íšŒì‚¬ë‚´ê·œ ì±—ë´‡ ì§ì ‘ ë§Œë“¤ì–´ ë³´ê¸°</a></li>
</ul>
<pre class="python"><code>from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

system_template=&quot;&quot;&quot;
Use the following pieces of context to answer the users question shortly.
Given the following summaries of a long document and a question, create a final answer with references (&quot;SOURCES&quot;), use &quot;SOURCES&quot; in capital letters regardless of the number of sources.
If you don&#39;t know the answer, just say that &quot;I don&#39;t know&quot;, don&#39;t try to make up an answer.
----------------
{summaries}

You MUST answer in Korean and in Markdown format:&quot;&quot;&quot;

messages = [
    SystemMessagePromptTemplate.from_template(system_template),
    HumanMessagePromptTemplate.from_template(&quot;{question}&quot;)
]

prompt = ChatPromptTemplate.from_messages(messages)</code></pre>
<div id="chatgpt-ëª¨ë¸ì„-ì‚¬ìš©í•˜ì—¬-í•™ìŠµ" class="section level4">
<h4>ChatGPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ</h4>
<p>ChatGPTì˜ gpt-3.5-turboë¥¼ ì‚¬ìš©í•˜ì—¬ pdfë¥¼ í•™ìŠµ í•´ì¤€ë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ ë§ˆì§€ë§‰ìœ¼ë¡œ chain()í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ì¤€ë‹¤.</p>
<pre class="python"><code>chain_type_kwargs = {&quot;prompt&quot;: prompt}

llm = ChatOpenAI(model_name=&quot;gpt-3.5-turbo&quot;, temperature=0)  # Modify model_name if you have access to GPT-4

chain = RetrievalQAWithSourcesChain.from_chain_type(
    llm=llm,
    chain_type=&quot;stuff&quot;,
    retriever = retriever,
    return_source_documents=True,
    chain_type_kwargs=chain_type_kwargs
)</code></pre>
</div>
<div id="ê²°ê³¼-í™•ì¸" class="section level4">
<h4>ê²°ê³¼ í™•ì¸</h4>
<p>ì´ë ‡ê²Œ ì±…ì„ í•™ìŠµ ì‹œì¼œë³´ê³  ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì.</p>
<pre class="python"><code>query = &quot;ì£¼ì œê°€ ë­ì•¼?&quot;
result = chain(query)
result[&#39;answer&#39;]</code></pre>
<pre><code>ì£¼ì œëŠ” íŒŒì´ì¬ê³¼ AWSë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ì²˜ë¦¬ ì…ë‹ˆë‹¤.</code></pre>
</div>
</div>
</div>
<div id="streamlit-ì—°ë™" class="section level2">
<h2>Streamlit ì—°ë™</h2>
<p>ì´ë²ˆì—ëŠ” ì´ë¥¼ Streamlitì— ì—°ë™ í•´ë³´ì. ì§€ë‚œë²ˆì— AWSì™€ íŒŒì´ì¬ ì±…ì„ ë§Œë“¤ë©´ì„œ Streamlit ëŒ€ì‹œë³´ë“œë¥¼ ê°™ì´ ìƒì„± í–ˆëŠ”ë°, ê±°ê¸°ì— ìƒˆë¡œìš´ í˜ì´ì§€ë¥¼ ì¶”ê°€ í•˜ê³  ê±°ê¸°ì— ì±—ë´‡ì„ ë„£ì„ ì˜ˆì •ì´ë‹¤. streamlitì—ì„œë„ chatbotì„ ìœ„í•œ ê¸°ëŠ¥ì„ ì¶”ê°€ í•´ì£¼ì—ˆë‹¤. Streamlitì˜ ì±—ë´‡ ê¸°ëŠ¥ì€ ë‹¤ìŒì˜ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³  í•˜ì.</p>
<ul>
<li><a href="https://docs.streamlit.io/library/api-reference/chat">Streamlit-Chat elements</a></li>
</ul>
<div id="streamlit-ì½”ë“œ" class="section level3">
<h3>Streamlit ì½”ë“œ</h3>
<p>streamlitì— ë“¤ì–´ê°€ëŠ” ì½”ë“œëŠ” ìœ„ì˜ ì½”ë“œì™€ ë§¤ìš° í¡ì‚¬ í•˜ë‹¤. ë”°ë¼ì„œ, íŠ¹ì´ì‚¬í•­ê³¼ ì±—ë´‡ ì½”ë“œë§Œ ì„¤ëª… í•˜ê³  ì „ì²´ ì½”ë“œë¡œ ë§ˆë¬´ë¦¬ í•˜ë ¤ê³  í•œë‹¤.</p>
<div id="íŠ¹ì´ì‚¬í•­" class="section level4">
<h4>íŠ¹ì´ì‚¬í•­</h4>
<p>Streamlitì„ githubì— ì—°ë™ í• ë•Œ chromadb ì„¤ì¹˜ê°€ ì˜ ë˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆë‹¤. ê·¸ëŸ´ë•Œ ë°°í¬í•˜ëŠ” íŒŒì´ì¬ì„ 3.10ìœ¼ë¡œ í•´ì£¼ê³  ë‹¤ìŒì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜ í•´ì£¼ë©´ ëœë‹¤.</p>
<pre class="python"><code>import pysqlite3
import sys
sys.modules[&#39;sqlite3&#39;] = sys.modules.pop(&#39;pysqlite3&#39;)
import streamlit as st
import sqlite3</code></pre>
</div>
<div id="streamlit-chatbot" class="section level4">
<h4>streamlit chatbot</h4>
<p>ë‹¤ìŒì€ Stremalit ì „ìš© ì±—ë´‡ ì½”ë“œ ì´ë‹¤.</p>
<pre class="python"><code>if &quot;messages&quot; not in st.session_state:
    st.session_state[&quot;messages&quot;] = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;ì§ˆë¬¸ì„ ì ì–´ ì£¼ì„¸ìš” ë¬´ì—‡ì„ ë„ì™€ ë“œë¦´ê¹Œìš”?&quot;}]

for msg in st.session_state.messages:
    st.chat_message(msg[&quot;role&quot;]).write(msg[&quot;content&quot;])

if prompt := st.chat_input():
    st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})
    st.chat_message(&quot;user&quot;).write(prompt)
    msg =  generate_response(prompt)
    st.session_state.messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: msg})
    st.chat_message(&quot;assistant&quot;).write(msg)    </code></pre>
</div>
<div id="ì „ì²´-ì½”ë“œ" class="section level4">
<h4>ì „ì²´ ì½”ë“œ</h4>
<p>ì´ì œ Streamlit ì— ë“¤ì–´ê°ˆ ì „ì²´ ì½”ë“œë¡œ ë§ˆë¬´ë¦¬</p>
<pre class="python"><code>import pysqlite3
import sys
sys.modules[&#39;sqlite3&#39;] = sys.modules.pop(&#39;pysqlite3&#39;)
import streamlit as st
import sqlite3


from langchain.llms import OpenAI

from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.embeddings.cohere import CohereEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch
from langchain.vectorstores import Chroma

import os

from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQAWithSourcesChain



st.set_page_config(
    page_title=&quot;ì§ˆì˜ì‘ë‹µì±—ë´‡&quot;,
    page_icon=&quot;ğŸ¤–&quot;,
    layout=&quot;wide&quot;,
    initial_sidebar_state=&quot;expanded&quot;
)


os.environ[&quot;OPENAI_API_KEY&quot;] = &#39;OPENAI apikey&#39; # í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

loader = PyPDFLoader(&#39;í•™ìŠµì— í•„ìš”í•œ pdf íŒŒì¼.pdf&#39;)
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
vector_store = Chroma.from_documents(texts, embeddings)
retriever = vector_store.as_retriever(search_kwargs={&quot;k&quot;: 2})
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

system_template=&quot;&quot;&quot;Use the following pieces of context to answer the users question shortly.
Given the following summaries of a long document and a question, create a final answer with references (&quot;SOURCES&quot;), use &quot;SOURCES&quot; in capital letters regardless of the number of sources.
If you don&#39;t know the answer, just say that &quot;I don&#39;t know&quot;, don&#39;t try to make up an answer.
----------------
{summaries}

You MUST answer in Korean and in Markdown format:&quot;&quot;&quot;

messages = [
    SystemMessagePromptTemplate.from_template(system_template),
    HumanMessagePromptTemplate.from_template(&quot;{question}&quot;)
]

prompt = ChatPromptTemplate.from_messages(messages)


chain_type_kwargs = {&quot;prompt&quot;: prompt}

llm = ChatOpenAI(model_name=&quot;gpt-3.5-turbo&quot;, temperature=0)  # Modify model_name if you have access to GPT-4

chain = RetrievalQAWithSourcesChain.from_chain_type(
    llm=llm,
    chain_type=&quot;stuff&quot;,
    retriever = retriever,
    return_source_documents=True,
    chain_type_kwargs=chain_type_kwargs
)


st.subheader(&#39;ì§ˆë¬¸ì„ ì ì–´ ì£¼ì„¸ìš”&#39;)


def generate_response(input_text):
  result = chain(input_text)
  return result[&#39;answer&#39;]

if &quot;messages&quot; not in st.session_state:
    st.session_state[&quot;messages&quot;] = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;ì§ˆë¬¸ì„ ì ì–´ ì£¼ì„¸ìš” ë¬´ì—‡ì„ ë„ì™€ ë“œë¦´ê¹Œìš”?&quot;}]

for msg in st.session_state.messages:
    st.chat_message(msg[&quot;role&quot;]).write(msg[&quot;content&quot;])

if prompt := st.chat_input():
    st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})
    st.chat_message(&quot;user&quot;).write(prompt)
    msg =  generate_response(prompt)
    st.session_state.messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: msg})
    st.chat_message(&quot;assistant&quot;).write(msg)    

</code></pre>
</div>
</div>
</div>
<div id="ì´í‰" class="section level2">
<h2>ì´í‰</h2>
<p>ì´ë ‡ê²Œ langchainì„ ì‚¬ìš©í•˜ì—¬ pdfë¥¼ í•™ìŠµí•œ ë‚˜ë§Œì˜ ì±—ë´‡ì„ ë§Œë“¤ì–´ ë³´ì•˜ë‹¤. ê·¸ë¦¬ê³  Streamlitì— ë‚´ê°€ ì‘ì„±í•œ ì±…ì˜ pdfíŒŒì¼ì„ í•™ìŠµì‹œì¼œ ì±—ë´‡ì„ ë„£ì–´ ë´¤ë‹¤. ë­ì²´ì¸ê³¼ ë²¡í„° DBê°€ ìš”ìƒˆ ìì£¼ ë³´ì´ëŠ”ë°, ë‹¤ìŒì—ëŠ” ê·¸ê²ƒë„ ê±´ë“œë ¤ë´ì•¼ ê² ë‹¤.</p>
<hr />
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<ul>
<li><a href="https://aifactory.space/task/2446/overview">ë„ì… ì‹œê¸‰! íšŒì‚¬ë‚´ê·œ ì±—ë´‡ ì§ì ‘ ë§Œë“¤ì–´ë³´ê¸° | ê¹€íƒœì˜</a></li>
<li><a href="https://www.youtube.com/watch?v=2yv4PxE1Ks0">ì¸ê³µì§€ëŠ¥íŒ©í† ë¦¬ ìœ íŠœë¸Œ-íšŒì‚¬ë‚´ê·œ ì±—ë´‡ ì§ì ‘ ë§Œë“¤ì–´ ë³´ê¸°</a></li>
<li><a href="https://anpigon.tistory.com/389">ChatGPT AIì— ì†Œì„¤ì„ í•™ìŠµì‹œí‚¨ ë‹¤ìŒ ì§ˆë¬¸í•˜ê¸°</a></li>
<li><a href="https://streamlit.io/gallery?category=llms">Streamlit LLM Gallery</a></li>
</ul>
</div>
