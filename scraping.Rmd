---
title: "인문 데이터 분석"
author: "유예림"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: readable
    highlight: textmate
    toc: yes
    toc_float: yes
    df_print: paged
  word_document: default
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  message = FALSE, warning = FALSE, 
                      fig.align = "center", fig.width = 10)
```

# 뉴스 기사 스크래핑


### 1. 라이브러리

```{r}
library(tidyverse)
library(wordcloud2)
library(rvest)
library(udpipe)
```

### 2. 네이버 뉴스 링크 추출

- page_num: 네이버 페이지
- 키워드: 비인기 종목 활성화 
- read_html() 함수를 통해 각각 링크의 html 코드 추출
- html_nodes() 를 통해 해당 class를 추출
- str_detect()를 통해 naver, main url 추출
- map_dfr()함수를 통해 url 병렬 처리


```{r}
page_num <- c(1,11,21,31,41,51, 61, 71, 81)

url_df <- map_dfr(page_num, function(x) {
  news_url <- paste0("https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EB%B9%84%EC%9D%B8%EA%B8%B0%20%EC%A2%85%EB%AA%A9%20%ED%99%9C%EC%84%B1%ED%99%94&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=15&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=",x)
  
  news_html <- read_html(news_url)
  
  news_urls <- news_html %>% 
    html_nodes(".info_group") %>% 
    html_nodes("a") %>% 
    html_attr("href")
  
  news_urls %>% 
    as_tibble() %>% 
    filter(str_detect(value, "naver")) %>% 
    filter(str_detect(value, "main"))
})


```

#### 2-1. 추출된 url

```{r}
url_df
```

### 3. 뉴스 기사 제목/본문 추출

- read_html() 함수를 통해 각각 링크의 html 코드 추출
- html_nodes() 를 통해 해당 class를 추출
- map_dfr()함수를 통해 url 병렬 처리

```{r}
news_total_df <- map_dfr(url_df$value, function(x) {
  title <- x %>% 
    read_html() %>% 
    html_nodes(".media_end_head_title") %>% 
    html_text() %>% 
    str_remove_all("\n|\t")  
  
  
  # body
  body <- x %>% 
    read_html() %>% 
    html_nodes("#newsct_article.newsct_article._article_body") %>% 
    html_text() %>% 
    str_remove_all("\n|\t")  
  
  df <- data.frame("title" = title, 
             "body" = body)
  df
}) %>% 
  as_tibble()
```

#### 3-1. 추출된 뉴스 기사/본문

```{r}
news_total_df
```

### 4. 자연어 처리 

- udpipe 라이브러리 사용
- upos 필터를 통해 NOUN(명사)추출

```{r}
udpipe_download_model(language = "korean")

model <- udpipe::udpipe_load_model("korean-gsd-ud-2.5-191206.udpipe")

news_annotate <- udpipe_annotate(model, news_total_df$body) %>% 
  as_tibble()

word.freq <- news_annotate %>% 
  filter(upos == "NOUN") %>% 
  select(token) %>% 
  count(token, sort = TRUE) %>% 
  filter(nchar(token) >= 2 & n >=2) %>% 
  rename(word = token, freq = n)


```

#### 4-1. 생성된 단어 빈도

```{r}
word.freq
```

### 5. 시각화

#### 5-1. 빈도 바플롯

```{r}
ggplot(head(word.freq,30), aes(x=reorder(word,freq),y=freq,fill=word),colour=gradient) +
  geom_col() +
  theme_bw() + 
  labs(x="",y="단어 빈도",title = "비인기 종목 해결 방안 뉴스 단어 빈도") + 
  coord_flip() + 
  theme(legend.position = "none") +
  theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1))
```

#### 5-2. 빈도 Wordcloud

```{r}
wordcloud2(word.freq,
           fontFamily="Malgun Gothic",
           size = 0.5,
           minRotation=0,
           maxRotation=0,
)
```

